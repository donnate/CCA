{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from model import CCA_SSG, LogReg\n",
    "from aug import random_aug\n",
    "from dataset import load\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from util import mask_test_edges_dgl\n",
    "import dgl\n",
    "import torch.nn.functional as F\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser.add_argument('--gpu', type=int, default=0, help='GPU index.')\n",
    "# parser.add_argument('--use_mlp', action='store_true', default=False, help='Use MLP instead of GNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_para(adj):\n",
    "    pos_weight = ((adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum())\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "    weight_mask = adj.view(-1) == 1\n",
    "    weight_tensor = th.ones(weight_mask.size(0))\n",
    "    weight_tensor[weight_mask] = pos_weight\n",
    "    return weight_tensor, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(edges_pos, edges_neg, adj_rec):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    adj_rec = adj_rec.cpu()\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
    "\n",
    "    preds_neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "graph, feat, labels, num_class, train_idx, val_idx, test_idx = load('cora')\n",
    "adj_orig = graph.adj().to_dense()\n",
    "train_edge_idx, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges_dgl(graph, adj_orig)\n",
    "\n",
    "# create train graph\n",
    "train_edge_idx = th.tensor(train_edge_idx)\n",
    "train_graph = dgl.edge_subgraph(graph, train_edge_idx, preserve_nodes=True)\n",
    "\n",
    "# add self loop\n",
    "#train_graph = dgl.remove_self_loop(train_graph)\n",
    "#train_graph = dgl.add_self_loop(train_graph)\n",
    "#n_edges = train_graph.number_of_edges()\n",
    "#adj = train_graph.adjacency_matrix().to_dense()\n",
    "\n",
    "# normalization\n",
    "#degs = train_graph.in_degrees().float()\n",
    "#norm = th.pow(degs, -0.5)\n",
    "#norm[th.isinf(norm)] = 0\n",
    "#train_graph.ndata['norm'] = norm.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=000, loss=-335.8493\n",
      "Epoch=001, loss=-342.0265\n",
      "Epoch=002, loss=-362.4157\n",
      "Epoch=003, loss=-382.1460\n",
      "Epoch=004, loss=-396.3875\n",
      "Epoch=005, loss=-381.8439\n",
      "Epoch=006, loss=-388.4731\n",
      "Epoch=007, loss=-387.4223\n",
      "Epoch=008, loss=-404.9112\n",
      "Epoch=009, loss=-405.2298\n",
      "Epoch=010, loss=-410.5345\n",
      "Epoch=011, loss=-419.2475\n",
      "Epoch=012, loss=-416.3677\n",
      "Epoch=013, loss=-412.4417\n",
      "Epoch=014, loss=-414.8666\n",
      "Epoch=015, loss=-416.0368\n",
      "Epoch=016, loss=-412.0549\n",
      "Epoch=017, loss=-417.2782\n",
      "Epoch=018, loss=-418.3943\n",
      "Epoch=019, loss=-432.0712\n",
      "Epoch=020, loss=-420.9087\n",
      "Epoch=021, loss=-427.2425\n",
      "Epoch=022, loss=-424.4462\n",
      "Epoch=023, loss=-433.9296\n",
      "Epoch=024, loss=-431.0464\n",
      "Epoch=025, loss=-433.8957\n",
      "Epoch=026, loss=-433.3944\n",
      "Epoch=027, loss=-433.0483\n",
      "Epoch=028, loss=-442.7434\n",
      "Epoch=029, loss=-436.7130\n",
      "Epoch=030, loss=-435.5874\n",
      "Epoch=031, loss=-437.5592\n",
      "Epoch=032, loss=-440.6771\n",
      "Epoch=033, loss=-445.4746\n",
      "Epoch=034, loss=-442.1152\n",
      "Epoch=035, loss=-436.9419\n",
      "Epoch=036, loss=-445.9366\n",
      "Epoch=037, loss=-443.0281\n",
      "Epoch=038, loss=-442.3124\n",
      "Epoch=039, loss=-446.2120\n",
      "Epoch=040, loss=-445.4206\n",
      "Epoch=041, loss=-449.2346\n",
      "Epoch=042, loss=-441.9646\n",
      "Epoch=043, loss=-444.2444\n",
      "Epoch=044, loss=-446.4854\n",
      "Epoch=045, loss=-446.7533\n",
      "Epoch=046, loss=-447.5259\n",
      "Epoch=047, loss=-448.7185\n",
      "Epoch=048, loss=-449.2794\n",
      "Epoch=049, loss=-445.6494\n",
      "Epoch=050, loss=-447.4362\n",
      "Epoch=051, loss=-450.3271\n",
      "Epoch=052, loss=-448.2715\n",
      "Epoch=053, loss=-450.9882\n",
      "Epoch=054, loss=-450.7107\n",
      "Epoch=055, loss=-449.5297\n",
      "Epoch=056, loss=-451.5963\n",
      "Epoch=057, loss=-452.1197\n",
      "Epoch=058, loss=-447.5221\n",
      "Epoch=059, loss=-456.1961\n",
      "Epoch=060, loss=-450.8959\n",
      "Epoch=061, loss=-448.7572\n",
      "Epoch=062, loss=-445.8690\n",
      "Epoch=063, loss=-451.7726\n",
      "Epoch=064, loss=-453.3704\n",
      "Epoch=065, loss=-451.4694\n",
      "Epoch=066, loss=-451.1746\n",
      "Epoch=067, loss=-455.8544\n",
      "Epoch=068, loss=-453.1239\n",
      "Epoch=069, loss=-456.7128\n",
      "Epoch=070, loss=-455.5745\n",
      "Epoch=071, loss=-454.0902\n",
      "Epoch=072, loss=-456.1933\n",
      "Epoch=073, loss=-450.2605\n",
      "Epoch=074, loss=-456.7446\n",
      "Epoch=075, loss=-453.4422\n",
      "Epoch=076, loss=-455.8007\n",
      "Epoch=077, loss=-455.0725\n",
      "Epoch=078, loss=-454.3239\n",
      "Epoch=079, loss=-455.5467\n",
      "Epoch=080, loss=-453.1435\n",
      "Epoch=081, loss=-456.2377\n",
      "Epoch=082, loss=-455.9160\n",
      "Epoch=083, loss=-455.2542\n",
      "Epoch=084, loss=-456.9015\n",
      "Epoch=085, loss=-457.3426\n",
      "Epoch=086, loss=-455.8110\n",
      "Epoch=087, loss=-456.7990\n",
      "Epoch=088, loss=-458.7935\n",
      "Epoch=089, loss=-461.3882\n",
      "Epoch=090, loss=-457.5330\n",
      "Epoch=091, loss=-457.6161\n",
      "Epoch=092, loss=-457.7907\n",
      "Epoch=093, loss=-456.8158\n",
      "Epoch=094, loss=-454.4820\n",
      "Epoch=095, loss=-460.0603\n",
      "Epoch=096, loss=-458.2931\n",
      "Epoch=097, loss=-459.4651\n",
      "Epoch=098, loss=-455.2679\n",
      "Epoch=099, loss=-459.5243\n"
     ]
    }
   ],
   "source": [
    "# graph, feat, labels, num_class, train_idx, val_idx, test_idx = load('cora')\n",
    "\n",
    "in_dim = feat.shape[1]\n",
    "\n",
    "hid_dim = 512\n",
    "out_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = CCA_SSG(in_dim, hid_dim, out_dim, n_layers, use_mlp=False)\n",
    "lr1 = 1e-3 \n",
    "wd1 = 0\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=lr1, weight_decay=wd1)\n",
    "\n",
    "N = graph.number_of_nodes()\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    dfr = 0.2\n",
    "    der = 0.2\n",
    "\n",
    "    graph1, feat1 = random_aug(graph, feat, 0.2, 0.2)\n",
    "    graph2, feat2 = random_aug(graph, feat, 0.2, 0.2)\n",
    "\n",
    "    graph1 = graph1.add_self_loop()\n",
    "    graph2 = graph2.add_self_loop()\n",
    "\n",
    "    z1, z2 = model(graph1, feat1, graph2, feat2)\n",
    "\n",
    "    c = th.mm(z1.T, z2)\n",
    "    c1 = th.mm(z1.T, z1)\n",
    "    c2 = th.mm(z2.T, z2)\n",
    "\n",
    "    c = c / N\n",
    "    c1 = c1 / N\n",
    "    c2 = c2 / N\n",
    "\n",
    "    loss_inv = -th.diagonal(c).sum()\n",
    "    iden = th.tensor(np.eye(c.shape[0]))\n",
    "    loss_dec1 = (iden - c1).pow(2).sum()\n",
    "    loss_dec2 = (iden - c2).pow(2).sum()\n",
    "    \n",
    "    lambd = 1e-3\n",
    "    \n",
    "    loss = loss_inv + lambd * (loss_dec1 + loss_dec2)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch={:03d}, loss={:.4f}'.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation ===\n",
      "0.9342036342400215 0.9343107150425899\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Evaluation ===\")\n",
    "graph = train_graph.remove_self_loop().add_self_loop()\n",
    "adj = graph.adj().to_dense()\n",
    "\n",
    "weight_tensor, norm = compute_loss_para(adj)\n",
    "\n",
    "embeds = model.get_embedding(graph, feat)\n",
    "\n",
    "# loss_fn = F.binary_cross_entropy\n",
    "loss_fn = F.binary_cross_entropy\n",
    "output_activation = nn.Sigmoid()\n",
    "logreg = LogReg(embeds.shape[1], adj.shape[1])\n",
    "\n",
    "logits_temp = logreg(embeds)\n",
    "logits = output_activation(th.mm(logits_temp, logits_temp.t()))\n",
    "\n",
    "val_roc, val_ap = get_scores(val_edges, val_edges_false, logits)\n",
    "test_roc, test_ap = get_scores(test_edges, test_edges_false, logits)\n",
    "print(test_roc, test_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation ===\n",
      "Epoch:0, val_ap:0.9409, val_roc:0.942404, test_ap:0.935086, test_roc:0.936019\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:1, val_ap:0.6876, val_roc:0.663431, test_ap:0.693164, test_roc:0.665078\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:2, val_ap:0.6700, val_roc:0.635526, test_ap:0.678623, test_roc:0.641258\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:3, val_ap:0.6900, val_roc:0.658134, test_ap:0.695163, test_roc:0.661009\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:4, val_ap:0.7310, val_roc:0.705915, test_ap:0.734049, test_roc:0.704682\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:5, val_ap:0.7968, val_roc:0.776656, test_ap:0.798646, test_roc:0.773840\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:6, val_ap:0.8477, val_roc:0.832880, test_ap:0.855743, test_roc:0.839316\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:7, val_ap:0.8705, val_roc:0.861048, test_ap:0.878230, test_roc:0.867245\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:8, val_ap:0.8861, val_roc:0.880279, test_ap:0.893746, test_roc:0.887368\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:9, val_ap:0.9017, val_roc:0.899787, test_ap:0.908291, test_roc:0.906527\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:10, val_ap:0.9138, val_roc:0.915428, test_ap:0.920311, test_roc:0.922224\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:11, val_ap:0.9221, val_roc:0.925550, test_ap:0.927108, test_roc:0.931159\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:12, val_ap:0.9263, val_roc:0.930551, test_ap:0.930500, test_roc:0.935508\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:13, val_ap:0.9292, val_roc:0.933763, test_ap:0.932278, test_roc:0.937585\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:14, val_ap:0.9319, val_roc:0.936560, test_ap:0.933828, test_roc:0.939144\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:15, val_ap:0.9350, val_roc:0.939794, test_ap:0.935941, test_roc:0.941214\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9360\n",
      "Epoch:16, val_ap:0.9384, val_roc:0.943103, test_ap:0.938514, test_roc:0.943748\n",
      "Linear evaluation AP:0.9351\n",
      "Linear evaluation ROC:0.9437\n",
      "Epoch:17, val_ap:0.9413, val_roc:0.946052, test_ap:0.940949, test_roc:0.946149\n",
      "Linear evaluation AP:0.9409\n",
      "Linear evaluation ROC:0.9461\n",
      "Epoch:18, val_ap:0.9437, val_roc:0.948551, test_ap:0.942922, test_roc:0.948108\n",
      "Linear evaluation AP:0.9429\n",
      "Linear evaluation ROC:0.9481\n",
      "Epoch:19, val_ap:0.9454, val_roc:0.950376, test_ap:0.944422, test_roc:0.949534\n",
      "Linear evaluation AP:0.9444\n",
      "Linear evaluation ROC:0.9495\n",
      "Epoch:20, val_ap:0.9469, val_roc:0.951791, test_ap:0.945513, test_roc:0.950577\n",
      "Linear evaluation AP:0.9455\n",
      "Linear evaluation ROC:0.9506\n",
      "Epoch:21, val_ap:0.9484, val_roc:0.953156, test_ap:0.946381, test_roc:0.951379\n",
      "Linear evaluation AP:0.9464\n",
      "Linear evaluation ROC:0.9514\n",
      "Epoch:22, val_ap:0.9495, val_roc:0.954229, test_ap:0.946860, test_roc:0.951940\n",
      "Linear evaluation AP:0.9469\n",
      "Linear evaluation ROC:0.9519\n",
      "Epoch:23, val_ap:0.9504, val_roc:0.955197, test_ap:0.947200, test_roc:0.952402\n",
      "Linear evaluation AP:0.9472\n",
      "Linear evaluation ROC:0.9524\n",
      "Epoch:24, val_ap:0.9512, val_roc:0.955957, test_ap:0.947565, test_roc:0.952846\n",
      "Linear evaluation AP:0.9476\n",
      "Linear evaluation ROC:0.9528\n",
      "Epoch:25, val_ap:0.9520, val_roc:0.956976, test_ap:0.947830, test_roc:0.953183\n",
      "Linear evaluation AP:0.9478\n",
      "Linear evaluation ROC:0.9532\n",
      "Epoch:26, val_ap:0.9525, val_roc:0.957693, test_ap:0.948253, test_roc:0.953713\n",
      "Linear evaluation AP:0.9483\n",
      "Linear evaluation ROC:0.9537\n",
      "Epoch:27, val_ap:0.9533, val_roc:0.958506, test_ap:0.948854, test_roc:0.954347\n",
      "Linear evaluation AP:0.9489\n",
      "Linear evaluation ROC:0.9543\n",
      "Epoch:28, val_ap:0.9539, val_roc:0.959212, test_ap:0.949446, test_roc:0.954982\n",
      "Linear evaluation AP:0.9494\n",
      "Linear evaluation ROC:0.9550\n",
      "Epoch:29, val_ap:0.9543, val_roc:0.959677, test_ap:0.950286, test_roc:0.955794\n",
      "Linear evaluation AP:0.9503\n",
      "Linear evaluation ROC:0.9558\n",
      "Epoch:30, val_ap:0.9547, val_roc:0.960076, test_ap:0.951122, test_roc:0.956530\n",
      "Linear evaluation AP:0.9511\n",
      "Linear evaluation ROC:0.9565\n",
      "Epoch:31, val_ap:0.9555, val_roc:0.960623, test_ap:0.951831, test_roc:0.957173\n",
      "Linear evaluation AP:0.9518\n",
      "Linear evaluation ROC:0.9572\n",
      "Epoch:32, val_ap:0.9560, val_roc:0.961088, test_ap:0.952445, test_roc:0.957816\n",
      "Linear evaluation AP:0.9524\n",
      "Linear evaluation ROC:0.9578\n",
      "Epoch:33, val_ap:0.9566, val_roc:0.961444, test_ap:0.953069, test_roc:0.958465\n",
      "Linear evaluation AP:0.9531\n",
      "Linear evaluation ROC:0.9585\n",
      "Epoch:34, val_ap:0.9570, val_roc:0.961693, test_ap:0.953476, test_roc:0.958954\n",
      "Linear evaluation AP:0.9535\n",
      "Linear evaluation ROC:0.9590\n",
      "Epoch:35, val_ap:0.9571, val_roc:0.961729, test_ap:0.953750, test_roc:0.959305\n",
      "Linear evaluation AP:0.9537\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:36, val_ap:0.9570, val_roc:0.961682, test_ap:0.953919, test_roc:0.959522\n",
      "Linear evaluation AP:0.9537\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:37, val_ap:0.9571, val_roc:0.961646, test_ap:0.953869, test_roc:0.959521\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:38, val_ap:0.9572, val_roc:0.961567, test_ap:0.953758, test_roc:0.959420\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:39, val_ap:0.9570, val_roc:0.961394, test_ap:0.953574, test_roc:0.959260\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:40, val_ap:0.9570, val_roc:0.961308, test_ap:0.953337, test_roc:0.959043\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:41, val_ap:0.9571, val_roc:0.961272, test_ap:0.953142, test_roc:0.958841\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:42, val_ap:0.9571, val_roc:0.961174, test_ap:0.953019, test_roc:0.958696\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:43, val_ap:0.9572, val_roc:0.961347, test_ap:0.952861, test_roc:0.958569\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:44, val_ap:0.9574, val_roc:0.961491, test_ap:0.952780, test_roc:0.958552\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:45, val_ap:0.9576, val_roc:0.961758, test_ap:0.952808, test_roc:0.958571\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:46, val_ap:0.9579, val_roc:0.961963, test_ap:0.952860, test_roc:0.958618\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:47, val_ap:0.9581, val_roc:0.962132, test_ap:0.952901, test_roc:0.958654\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:48, val_ap:0.9584, val_roc:0.962381, test_ap:0.952976, test_roc:0.958714\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:49, val_ap:0.9586, val_roc:0.962546, test_ap:0.953060, test_roc:0.958772\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:50, val_ap:0.9587, val_roc:0.962640, test_ap:0.953140, test_roc:0.958843\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:51, val_ap:0.9588, val_roc:0.962755, test_ap:0.953258, test_roc:0.958932\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:52, val_ap:0.9590, val_roc:0.962877, test_ap:0.953372, test_roc:0.959022\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:53, val_ap:0.9591, val_roc:0.963007, test_ap:0.953620, test_roc:0.959225\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9593\n",
      "Epoch:54, val_ap:0.9592, val_roc:0.963086, test_ap:0.953837, test_roc:0.959409\n",
      "Linear evaluation AP:0.9539\n",
      "Linear evaluation ROC:0.9594\n",
      "Epoch:55, val_ap:0.9593, val_roc:0.963169, test_ap:0.954041, test_roc:0.959562\n",
      "Linear evaluation AP:0.9540\n",
      "Linear evaluation ROC:0.9596\n",
      "Epoch:56, val_ap:0.9594, val_roc:0.963270, test_ap:0.954233, test_roc:0.959711\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9597\n",
      "Epoch:57, val_ap:0.9593, val_roc:0.963310, test_ap:0.954330, test_roc:0.959798\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n",
      "Epoch:58, val_ap:0.9593, val_roc:0.963335, test_ap:0.954355, test_roc:0.959833\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n",
      "Epoch:59, val_ap:0.9592, val_roc:0.963209, test_ap:0.954373, test_roc:0.959867\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n",
      "Epoch:60, val_ap:0.9592, val_roc:0.963191, test_ap:0.954363, test_roc:0.959879\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:61, val_ap:0.9591, val_roc:0.963119, test_ap:0.954320, test_roc:0.959889\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n",
      "Epoch:62, val_ap:0.9591, val_roc:0.963101, test_ap:0.954299, test_roc:0.959898\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n",
      "Epoch:63, val_ap:0.9591, val_roc:0.963137, test_ap:0.954279, test_roc:0.959902\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n",
      "Epoch:64, val_ap:0.9591, val_roc:0.963155, test_ap:0.954238, test_roc:0.959916\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n",
      "Epoch:65, val_ap:0.9592, val_roc:0.963180, test_ap:0.954233, test_roc:0.959930\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n",
      "Epoch:66, val_ap:0.9592, val_roc:0.963223, test_ap:0.954213, test_roc:0.959929\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n",
      "Epoch:67, val_ap:0.9593, val_roc:0.963302, test_ap:0.954205, test_roc:0.959943\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9598\n",
      "Epoch:68, val_ap:0.9594, val_roc:0.963364, test_ap:0.954195, test_roc:0.959946\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9599\n",
      "Epoch:69, val_ap:0.9595, val_roc:0.963457, test_ap:0.954174, test_roc:0.959969\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9600\n",
      "Epoch:70, val_ap:0.9596, val_roc:0.963482, test_ap:0.954210, test_roc:0.960018\n",
      "Linear evaluation AP:0.9542\n",
      "Linear evaluation ROC:0.9600\n",
      "Epoch:71, val_ap:0.9597, val_roc:0.963554, test_ap:0.954272, test_roc:0.960079\n",
      "Linear evaluation AP:0.9543\n",
      "Linear evaluation ROC:0.9601\n",
      "Epoch:72, val_ap:0.9597, val_roc:0.963601, test_ap:0.954302, test_roc:0.960116\n",
      "Linear evaluation AP:0.9543\n",
      "Linear evaluation ROC:0.9601\n",
      "Epoch:73, val_ap:0.9598, val_roc:0.963680, test_ap:0.954352, test_roc:0.960164\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9602\n",
      "Epoch:74, val_ap:0.9598, val_roc:0.963709, test_ap:0.954389, test_roc:0.960190\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9602\n",
      "Epoch:75, val_ap:0.9598, val_roc:0.963720, test_ap:0.954429, test_roc:0.960224\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9602\n",
      "Epoch:76, val_ap:0.9598, val_roc:0.963724, test_ap:0.954495, test_roc:0.960270\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:77, val_ap:0.9597, val_roc:0.963691, test_ap:0.954493, test_roc:0.960269\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:78, val_ap:0.9597, val_roc:0.963688, test_ap:0.954494, test_roc:0.960278\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:79, val_ap:0.9597, val_roc:0.963673, test_ap:0.954537, test_roc:0.960296\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:80, val_ap:0.9596, val_roc:0.963619, test_ap:0.954547, test_roc:0.960306\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:81, val_ap:0.9596, val_roc:0.963601, test_ap:0.954548, test_roc:0.960320\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:82, val_ap:0.9596, val_roc:0.963587, test_ap:0.954540, test_roc:0.960330\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:83, val_ap:0.9596, val_roc:0.963594, test_ap:0.954538, test_roc:0.960335\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:84, val_ap:0.9596, val_roc:0.963608, test_ap:0.954530, test_roc:0.960343\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:85, val_ap:0.9596, val_roc:0.963612, test_ap:0.954534, test_roc:0.960358\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:86, val_ap:0.9597, val_roc:0.963626, test_ap:0.954507, test_roc:0.960359\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:87, val_ap:0.9597, val_roc:0.963648, test_ap:0.954491, test_roc:0.960385\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:88, val_ap:0.9597, val_roc:0.963670, test_ap:0.954496, test_roc:0.960410\n",
      "Linear evaluation AP:0.9544\n",
      "Linear evaluation ROC:0.9603\n",
      "Epoch:89, val_ap:0.9598, val_roc:0.963724, test_ap:0.954490, test_roc:0.960424\n",
      "Linear evaluation AP:0.9545\n",
      "Linear evaluation ROC:0.9604\n",
      "Epoch:90, val_ap:0.9599, val_roc:0.963788, test_ap:0.954519, test_roc:0.960457\n",
      "Linear evaluation AP:0.9545\n",
      "Linear evaluation ROC:0.9605\n",
      "Epoch:91, val_ap:0.9599, val_roc:0.963821, test_ap:0.954538, test_roc:0.960478\n",
      "Linear evaluation AP:0.9545\n",
      "Linear evaluation ROC:0.9605\n",
      "Epoch:92, val_ap:0.9600, val_roc:0.963835, test_ap:0.954551, test_roc:0.960487\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9605\n",
      "Epoch:93, val_ap:0.9600, val_roc:0.963835, test_ap:0.954561, test_roc:0.960500\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9605\n",
      "Epoch:94, val_ap:0.9600, val_roc:0.963828, test_ap:0.954592, test_roc:0.960519\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9605\n",
      "Epoch:95, val_ap:0.9600, val_roc:0.963850, test_ap:0.954592, test_roc:0.960523\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9605\n",
      "Epoch:96, val_ap:0.9599, val_roc:0.963835, test_ap:0.954599, test_roc:0.960526\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9605\n",
      "Epoch:97, val_ap:0.9599, val_roc:0.963850, test_ap:0.954626, test_roc:0.960540\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9605\n",
      "Epoch:98, val_ap:0.9599, val_roc:0.963850, test_ap:0.954651, test_roc:0.960562\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9605\n",
      "Epoch:99, val_ap:0.9599, val_roc:0.963853, test_ap:0.954673, test_roc:0.960579\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9606\n",
      "Epoch:100, val_ap:0.9599, val_roc:0.963850, test_ap:0.954685, test_roc:0.960587\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9606\n",
      "Epoch:101, val_ap:0.9599, val_roc:0.963853, test_ap:0.954683, test_roc:0.960586\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9606\n",
      "Epoch:102, val_ap:0.9599, val_roc:0.963868, test_ap:0.954692, test_roc:0.960599\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9606\n",
      "Epoch:103, val_ap:0.9599, val_roc:0.963878, test_ap:0.954678, test_roc:0.960609\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9606\n",
      "Epoch:104, val_ap:0.9599, val_roc:0.963904, test_ap:0.954684, test_roc:0.960624\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9606\n",
      "Epoch:105, val_ap:0.9600, val_roc:0.963922, test_ap:0.954663, test_roc:0.960625\n",
      "Linear evaluation AP:0.9546\n",
      "Linear evaluation ROC:0.9606\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Evaluation ===\")\n",
    "graph = train_graph.remove_self_loop().add_self_loop()\n",
    "adj = graph.adj().to_dense()\n",
    "\n",
    "weight_tensor, norm = compute_loss_para(adj)\n",
    "\n",
    "embeds = model.get_embedding(graph, feat)\n",
    "\n",
    "''' Linear Evaluation '''\n",
    "logreg = LogReg(embeds.shape[1], adj.shape[1])\n",
    "lr2 = 1e-2\n",
    "wd2 = 1e-4\n",
    "opt = th.optim.Adam(logreg.parameters(), lr=lr2, weight_decay=wd2)\n",
    "\n",
    "loss_fn = F.binary_cross_entropy\n",
    "output_activation = nn.Sigmoid()\n",
    "\n",
    "best_val_roc = 0\n",
    "eval_roc = 0\n",
    "best_val_ap = 0\n",
    "eval_ap = 0\n",
    "    \n",
    "for epoch in range(2000):\n",
    "    logreg.train()\n",
    "    opt.zero_grad()\n",
    "    logits_temp = logreg(embeds)\n",
    "    logits = output_activation(th.mm(logits_temp, logits_temp.t()))\n",
    "    \n",
    "    # pdb.set_trace()\n",
    "    loss = norm*loss_fn(logits.view(-1), adj.view(-1), weight = weight_tensor)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    logreg.eval()\n",
    "    with th.no_grad():\n",
    "        val_roc, val_ap = get_scores(val_edges, val_edges_false, logits)\n",
    "        test_roc, test_ap = get_scores(test_edges, test_edges_false, logits)\n",
    "\n",
    "        if val_roc >= best_val_roc:\n",
    "            best_val_roc = val_roc\n",
    "            if test_roc > eval_roc:\n",
    "                eval_roc = test_roc\n",
    "        \n",
    "        if val_ap >= best_val_ap:\n",
    "            best_val_ap = val_ap\n",
    "            if test_ap > eval_ap:\n",
    "                eval_ap = test_ap\n",
    "\n",
    "    print('Epoch:{}, val_ap:{:.4f}, val_roc:{:4f}, test_ap:{:4f}, test_roc:{:4f}'.format(epoch, val_ap, val_roc, test_ap, test_roc))\n",
    "    print('Linear evaluation AP:{:.4f}'.format(eval_ap))\n",
    "    print('Linear evaluation ROC:{:.4f}'.format(eval_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
