{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "%matplotlib inline\n",
    "import sys,os\n",
    "sys.path.append('../../')\n",
    "\n",
    "\n",
    "from model import CCA_SSG, LogReg\n",
    "from aug import random_aug\n",
    "from dataset import load\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from util import mask_test_edges_dgl\n",
    "import dgl\n",
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "\n",
    "\n",
    "def compute_loss_para(adj):\n",
    "    pos_weight = ((adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum())\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "    weight_mask = adj.view(-1) == 1\n",
    "    weight_tensor = th.ones(weight_mask.size(0))\n",
    "    weight_tensor[weight_mask] = pos_weight\n",
    "    return weight_tensor, norm\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def get_scores(edges_pos, edges_neg, adj_rec):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    adj_rec = adj_rec.cpu()\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
    "\n",
    "    preds_neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score\n",
    "\n",
    "\n",
    "# In[5]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCA_SSG_enhanced(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, n_layers, use_mlp = False):\n",
    "        super().__init__()\n",
    "        if not use_mlp:\n",
    "            self.backbone = GCN(in_dim, hid_dim, out_dim, n_layers)\n",
    "        else:\n",
    "            self.backbone = MLP(in_dim, hid_dim, out_dim)\n",
    "\n",
    "    def get_embedding(self, graph, feat):\n",
    "        out = self.backbone(graph, feat)\n",
    "        return out.detach()\n",
    "\n",
    "    def forward(self, graph1, feat1, graph2, feat2):\n",
    "        h1 = self.backbone(graph1, feat1)\n",
    "        h2 = self.backbone(graph2, feat2)\n",
    "        \n",
    "        z1 = (h1 - h1.mean(0)) / h1.std(0)\n",
    "        z2 = (h2 - h2.mean(0)) / h2.std(0)\n",
    "\n",
    "        return z1, z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2fe72ebb1b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mSTOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mloss_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0miden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "graph, feat, labels, num_class, train_idx, val_idx, test_idx = load('cora')\n",
    "adj_orig = graph.adj().to_dense()\n",
    "train_edge_idx, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges_dgl(graph, adj_orig)\n",
    "\n",
    "# create train graph\n",
    "train_edge_idx = th.tensor(train_edge_idx)\n",
    "train_graph = dgl.edge_subgraph(graph, train_edge_idx, preserve_nodes=True)\n",
    "\n",
    "# add self loop\n",
    "#train_graph = dgl.remove_self_loop(train_graph)\n",
    "#train_graph = dgl.add_self_loop(train_graph)\n",
    "#n_edges = train_graph.number_of_edges()\n",
    "#adj = train_graph.adjacency_matrix().to_dense()\n",
    "\n",
    "# normalization\n",
    "#degs = train_graph.in_degrees().float()\n",
    "#norm = th.pow(degs, -0.5)\n",
    "#norm[th.isinf(norm)] = 0\n",
    "#train_graph.ndata['norm'] = norm.unsqueeze(1)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# graph, feat, labels, num_class, train_idx, val_idx, test_idx = load('cora')\n",
    "\n",
    "in_dim = feat.shape[1]\n",
    "\n",
    "hid_dim = 512\n",
    "out_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = CCA_SSG(in_dim, hid_dim, out_dim, n_layers, use_mlp=False)\n",
    "lr1 = 1e-3 \n",
    "wd1 = 0\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=lr1, weight_decay=wd1)\n",
    "\n",
    "N = graph.number_of_nodes()\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    dfr = 0.2\n",
    "    der = 0.2\n",
    "\n",
    "    graph1, feat1 = random_aug(graph, feat, 0.2, 0.2)\n",
    "    graph2, feat2 = random_aug(graph, feat, 0.2, 0.2)\n",
    "\n",
    "    graph1 = graph1.add_self_loop()\n",
    "    graph2 = graph2.add_self_loop()\n",
    "\n",
    "    z1, z2 = model(graph1, feat1, graph2, feat2)\n",
    "\n",
    "    c = th.mm(z1.T, z2)\n",
    "    c1 = th.mm(z1.T, z1)\n",
    "    c2 = th.mm(z2.T, z2)\n",
    "\n",
    "    c = c / N\n",
    "    c1 = c1 / N\n",
    "    c2 = c2 / N\n",
    "    STOP\n",
    "    loss_inv = -th.diagonal(c).sum()\n",
    "    iden = th.tensor(np.eye(c.shape[0]))\n",
    "    loss_dec1 = (iden - c1).pow(2).sum()\n",
    "    loss_dec2 = (iden - c2).pow(2).sum()\n",
    "    #### Add repulsion between terms\n",
    "    \n",
    "    \n",
    "    lambd = 1e-3\n",
    "    \n",
    "    loss = loss_inv + lambd * (loss_dec1 + loss_dec2)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch={:03d}, loss={:.4f}'.format(epoch, loss.item()))\n",
    "\n",
    "\n",
    "# In[7]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Evaluation ===\")\n",
    "graph = train_graph.remove_self_loop().add_self_loop()\n",
    "adj = graph.adj().to_dense()\n",
    "\n",
    "weight_tensor, norm = compute_loss_para(adj)\n",
    "\n",
    "embeds = model.get_embedding(graph, feat)\n",
    "\n",
    "# loss_fn = F.binary_cross_entropy\n",
    "loss_fn = F.binary_cross_entropy\n",
    "output_activation = nn.Sigmoid()\n",
    "logreg = LogReg(embeds.shape[1], adj.shape[1])\n",
    "\n",
    "logits_temp = logreg(embeds)\n",
    "logits = output_activation(th.mm(logits_temp, logits_temp.t()))\n",
    "\n",
    "val_roc, val_ap = get_scores(val_edges, val_edges_false, logits)\n",
    "test_roc, test_ap = get_scores(test_edges, test_edges_false, logits)\n",
    "print(test_roc, test_ap)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(\"=== Evaluation ===\")\n",
    "graph = train_graph.remove_self_loop().add_self_loop()\n",
    "adj = graph.adj().to_dense()\n",
    "\n",
    "weight_tensor, norm = compute_loss_para(adj)\n",
    "\n",
    "embeds = model.get_embedding(graph, feat)\n",
    "\n",
    "\n",
    "''' Linear Evaluation '''\n",
    "logreg = LogReg(embeds.shape[1], adj.shape[1])\n",
    "lr2 = 1e-2\n",
    "wd2 = 1e-4\n",
    "opt = th.optim.Adam(logreg.parameters(), lr=lr2, weight_decay=wd2)\n",
    "\n",
    "loss_fn = F.binary_cross_entropy\n",
    "output_activation = nn.Sigmoid()\n",
    "\n",
    "best_val_roc = 0\n",
    "eval_roc = 0\n",
    "best_val_ap = 0\n",
    "eval_ap = 0\n",
    "    \n",
    "for epoch in range(2000):\n",
    "    logreg.train()\n",
    "    opt.zero_grad()\n",
    "    logits_temp = logreg(embeds)\n",
    "    logits = output_activation(th.mm(logits_temp, logits_temp.t()))\n",
    "    \n",
    "    # pdb.set_trace()\n",
    "    loss = norm*loss_fn(logits.view(-1), adj.view(-1), weight = weight_tensor)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    logreg.eval()\n",
    "    with th.no_grad():\n",
    "        val_roc, val_ap = get_scores(val_edges, val_edges_false, logits)\n",
    "        test_roc, test_ap = get_scores(test_edges, test_edges_false, logits)\n",
    "\n",
    "        if val_roc >= best_val_roc:\n",
    "            best_val_roc = val_roc\n",
    "            if test_roc > eval_roc:\n",
    "                eval_roc = test_roc\n",
    "        \n",
    "        if val_ap >= best_val_ap:\n",
    "            best_val_ap = val_ap\n",
    "            if test_ap > eval_ap:\n",
    "                eval_ap = test_ap\n",
    "\n",
    "    print('Epoch:{}, val_ap:{:.4f}, val_roc:{:4f}, test_ap:{:4f}, test_roc:{:4f}'.format(epoch, val_ap, val_roc, test_ap, test_roc))\n",
    "    print('Linear evaluation AP:{:.4f}'.format(eval_ap))\n",
    "    print('Linear evaluation ROC:{:.4f}'.format(eval_roc))\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
